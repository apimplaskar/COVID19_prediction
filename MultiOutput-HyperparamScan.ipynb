{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import numpy as np\n",
    "import sklearn \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy.integrate import odeint\n",
    "from scipy.optimize import minimize\n",
    "from utility_code.utility import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainrd2 = pd.read_csv(\"train_round2.csv\")\n",
    "datestofind = trainrd2['Date'] == '09-01-2020'\n",
    "start = datestofind[datestofind == True].index[0]\n",
    "datestofind2 = trainrd2['Date'] == '09-26-2020'\n",
    "end = datestofind[datestofind == True].index[49]\n",
    "\n",
    "bestsub = pd.read_csv(\"team31-nov29-2.csv\")\n",
    "\n",
    "validation = trainrd2.iloc[start:end,:]\n",
    "def MAPE(pred, valid):\n",
    "    pred = pred.reset_index()\n",
    "    valid = valid.reset_index()\n",
    "    pred = pred.astype('int64')\n",
    "    valid = valid.astype('int64')\n",
    "    v = pred.subtract(valid)\n",
    "    v = v.divide(valid)\n",
    "    v = v.abs()\n",
    "    v = v.sum(axis = 0)\n",
    "    #v = v[0]+v[1]+v[2]\n",
    "    n = len(pred)\n",
    "    return v/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import csvs\n",
    "train = pd.read_csv(\"ucla2020-cs145-covid19-prediction/train.csv\")\n",
    "test = pd.read_csv(\"ucla2020-cs145-covid19-prediction/test.csv\")\n",
    "graph = pd.read_csv(\"ucla2020-cs145-covid19-prediction/graph.csv\")\n",
    "supp = pd.read_csv(\"data-test/raw_data_test.csv\", skiprows=2, thousands=',')\n",
    "supp = supp[supp['Location'].isin(train['Province_State'])]\n",
    "supp['Population'] = supp['Number of COVID-19 Cases'].divide(supp['COVID-19 Cases per 1,000,000 Population']) * 1e6\n",
    "\n",
    "states = pd.Series.unique(train['Province_State'])\n",
    "num_states = len(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting using previous best setup...\n",
      "(*) SETUP: Confirmed Error: 8.264506555201208e-05  | Deaths Error: 0.00017968191404611904\n",
      "(-) ITERATION 1: Confirmed Error: 8.332579213953679e-05  | Deaths Error: 0.000186474359543878\n",
      "(-) ITERATION 2: Confirmed Error: 9.794785079174812e-05  | Deaths Error: 0.0002007489199403362\n",
      "(-) ITERATION 3: Confirmed Error: 9.128299743429795e-05  | Deaths Error: 0.00019119433704191385\n",
      "(-) ITERATION 4: Confirmed Error: 9.812021535278148e-05  | Deaths Error: 0.0002007489199403362\n",
      "(*) ITERATION 5: Confirmed Error: 8.000969883068725e-05  | Deaths Error: 0.0001782893056527195\n",
      "(*) ITERATION 6: Confirmed Error: 9.138337344401038e-05  | Deaths Error: 0.00017420171962008045\n",
      "(-) ITERATION 7: Confirmed Error: 8.000969883068725e-05  | Deaths Error: 0.0001782893056527195\n",
      "(-) ITERATION 8: Confirmed Error: 8.009859641178407e-05  | Deaths Error: 0.0001782893056527195\n",
      "(-) ITERATION 9: Confirmed Error: 8.279028563304487e-05  | Deaths Error: 0.00017968191404611904\n",
      "(-) ITERATION 10: Confirmed Error: 9.162999953369308e-05  | Deaths Error: 0.00017420171962008045\n",
      "Found 3 good solutions!\n"
     ]
    }
   ],
   "source": [
    "## MANIPULATES MODEL AND MODEL PARAMS\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "import random\n",
    "\n",
    "###################################################\n",
    "#TRY DIFFERENT VALUES FOR PARAMETERS AND KEEP THE BEST\n",
    "best_parameter_setup = { 'alpha': 1.6625501873415338,\n",
    "                         'max_iter': 2267,\n",
    "                         'tol': 0.0018737851734607867,\n",
    "                         'random_state':229018,\n",
    "                         'window_size':5,\n",
    "                         'confirmed_error': 7.667212448385207e-05,\n",
    "                         'deaths_error': 0.00016738204091735175  }\n",
    "\n",
    "best_parameter_setups = [best_parameter_setup]\n",
    "confirmed_error_best = 1 \n",
    "deaths_error_best = 1\n",
    "\n",
    "#standard deviations: try increasing sd_scale for more variance (or decreasing for opposite effect)\n",
    "sd_scale = 8\n",
    "alpha_sd = 0.2 * sd_scale;\n",
    "max_iter_sd = 100 * sd_scale;\n",
    "tol_sd = 5e-4 * sd_scale;\n",
    "\n",
    "#returns sample taken from normal distribution, bounds the sample with min and max\n",
    "DEFAULT_MIN = 1e-25\n",
    "DEFAULT_MAX = 999999\n",
    "def normal_sample (mean,sd,mn,mx,rnd = False):\n",
    "    sample = max(mn, min(mx, np.random.normal(mean, sd)))\n",
    "    if rnd:\n",
    "        return int(sample)\n",
    "    else:\n",
    "        return sample\n",
    "\n",
    "\n",
    "ITERATIONS = 10\n",
    "parameter_setup = {}\n",
    "\n",
    "print(\"Starting using previous best setup...\")\n",
    "\n",
    "for it in range(ITERATIONS+1):\n",
    "    \n",
    "    #apply normal \"randomization\"\n",
    "    parameter_setup = {}\n",
    "    if it > 0:\n",
    "        parameter_setup['alpha'] = normal_sample( best_parameter_setups[-1]['alpha'], alpha_sd, DEFAULT_MIN, DEFAULT_MAX)\n",
    "        parameter_setup['max_iter'] = normal_sample( best_parameter_setups[-1]['max_iter'], max_iter_sd, 1, DEFAULT_MAX, rnd=True)\n",
    "        parameter_setup['tol'] = normal_sample( best_parameter_setups[-1]['tol'], tol_sd, DEFAULT_MIN, 20) \n",
    "        parameter_setup['random_state'] = random.randint(0,DEFAULT_MAX)\n",
    "        parameter_setup['window_size'] = random.randint(1,14)\n",
    "    else:\n",
    "        parameter_setup = best_parameter_setups[-1]\n",
    "    \n",
    "    \n",
    "    #choose a regressor\n",
    "    reg = MultiOutputRegressor(estimator=Ridge(\n",
    "                                    alpha=parameter_setup['alpha'],\n",
    "                                    max_iter=parameter_setup['max_iter'],\n",
    "                                    tol=parameter_setup['tol'],\n",
    "                                    random_state = parameter_setup['random_state']))\n",
    "        \n",
    "###################################################\n",
    "\n",
    "    ## MANIPULATES FEATURES FROM DF TO USE AND WINDOW SIZE\n",
    "    #only look at the features in features list\n",
    "    features = ['Confirmed','Deaths']\n",
    "    num_features = len(features)\n",
    "\n",
    "    #stratify by state (into state dictionary)\n",
    "    statesdata = {}\n",
    "    for s in states:\n",
    "        statesdata[s] = train.loc[train['Province_State'] == s,features]\n",
    "\n",
    "    \n",
    "    ###################################################\n",
    "    WINDOW_SIZE = parameter_setup['window_size']\n",
    "    ###################################################\n",
    "    \n",
    "    state_feature_indices = utils.get_column_indices(statesdata['California'],features)\n",
    "\n",
    "    #append the feature spaces from the W days prior (where W is the window length)\n",
    "    new_features = []\n",
    "    for day in range(WINDOW_SIZE):\n",
    "        for f in features:\n",
    "            new_features.append(f + \"(-\"+ str(WINDOW_SIZE-day) + \" days)\")\n",
    "    all_new_features = new_features + features\n",
    "\n",
    "    ## Set up dictionary of projections\n",
    "    proj = {}\n",
    "\n",
    "    ## Loop over states\n",
    "    for s in states:\n",
    "\n",
    "        a = statesdata[s]\n",
    "\n",
    "        #fill the knn data using days from training set\n",
    "        knndata = pd.DataFrame(columns = all_new_features)\n",
    "        num_training_days = len(statesdata['California'])\n",
    "\n",
    "        #fill the table\n",
    "        for d in range(WINDOW_SIZE,num_training_days):\n",
    "            knndata_row_index = knndata.shape[0]\n",
    "            knn_row = utils.flatten_dataframe(a,slice(d-WINDOW_SIZE,d+1), state_feature_indices)\n",
    "            utils.dataframe_append_row(knndata,knn_row,s,d)   \n",
    "\n",
    "        # Actual recursive prediction\n",
    "        days_to_predict = 26\n",
    "        for d in range(days_to_predict):\n",
    "            #x = knndata.drop(columns=features)\n",
    "            #y = knndata.drop(columns=features)\n",
    "            x = knndata.drop(['Confirmed', 'Deaths'], axis = 1)\n",
    "            y = knndata[['Confirmed', 'Deaths']]\n",
    "            toguess = 1\n",
    "            trainx = x.head(len(x))\n",
    "            trainy = y.head(len(y))\n",
    "            # testy = y.tail(toguess)\n",
    "\n",
    "            reg.fit(trainx, trainy)\n",
    "\n",
    "            #rmv = [i for i in range(num_features)]\n",
    "            #ftrs = knndata.drop(columns=knndata.columns[rmv]).tail(1)\n",
    "            ftrs = knndata.drop(columns=knndata.columns[[0,1]]).tail(1)\n",
    "            #ftrs.drop(columns=knndata.columns[[0,1]])\n",
    "\n",
    "            ftrs.columns = knndata.columns[0:num_features*WINDOW_SIZE]\n",
    "\n",
    "            new = reg.predict(ftrs)\n",
    "            ftrs = np.append(ftrs, new)\n",
    "            ftrs = ftrs.astype(int)\n",
    "            #if d==0: print(ftrs)\n",
    "            knndata = knndata.append(dict(zip(knndata.columns, ftrs)), ignore_index=True)\n",
    "\n",
    "            # append to knndata\n",
    "            #if d == 0: \n",
    "                #print(knndata)\n",
    "        done = knndata.tail(days_to_predict)\n",
    "        done = done[['Confirmed', 'Deaths']]\n",
    "        #print(done)\n",
    "        proj[s] = done\n",
    "\n",
    "    ## Get ordering of states in test    \n",
    "    order = test.loc[0:49,'Province_State']\n",
    "\n",
    "    # format submission\n",
    "    conf = []\n",
    "    dead = []\n",
    "    fid = 0\n",
    "    for i in range(days_to_predict):\n",
    "        for j in order:\n",
    "            projection = proj[j].iloc[i]\n",
    "            #print(j, 'day', i)\n",
    "            conf.append(int(projection['Confirmed']))\n",
    "            dead.append(int(projection['Deaths']))\n",
    "            #print(fid)\n",
    "            fid+=1\n",
    "\n",
    "    test['Confirmed'] = conf\n",
    "    test['Deaths'] = dead\n",
    "\n",
    "###################################################\n",
    "    errors = MAPE(test[['Confirmed', 'Deaths']], validation[['Confirmed', 'Deaths']])\n",
    "    parameter_setup['confirmed_error'] = errors['Confirmed']\n",
    "    parameter_setup['deaths_error'] = errors['Deaths']\n",
    "    \n",
    "    \n",
    "    found_good_sol = False\n",
    "    if(parameter_setup['confirmed_error'] < confirmed_error_best):\n",
    "        confirmed_error_best = parameter_setup['confirmed_error']\n",
    "        found_good_sol = True\n",
    "    if(parameter_setup['deaths_error'] < deaths_error_best):\n",
    "        deaths_error_best = parameter_setup['deaths_error']\n",
    "        found_good_sol = True\n",
    "    if found_good_sol:\n",
    "        best_parameter_setups.append(parameter_setup)\n",
    "        \n",
    "    if found_good_sol:\n",
    "        if it == 0:\n",
    "            print(\"(*) SETUP:\",\"Confirmed Error: \"+str(parameter_setup['confirmed_error']),\" | Deaths Error: \"+str(parameter_setup['deaths_error']))\n",
    "        else:\n",
    "            print(\"(*) ITERATION \"+str(it)+\":\",\"Confirmed Error: \"+str(parameter_setup['confirmed_error']),\" | Deaths Error: \"+str(parameter_setup['deaths_error']))\n",
    "    else:\n",
    "        if it == 0:\n",
    "            print(\"(-) SETUP:\",\"Confirmed Error: \"+str(parameter_setup['confirmed_error']),\" | Deaths Error: \"+str(parameter_setup['deaths_error']))\n",
    "        else:\n",
    "            print(\"(-) ITERATION \"+str(it)+\":\",\"Confirmed Error: \"+str(parameter_setup['confirmed_error']),\" | Deaths Error: \"+str(parameter_setup['deaths_error']))\n",
    "        \n",
    "        \n",
    "print(\"Found\",len(best_parameter_setups) - 1,\"good solutions!\")\n",
    "###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1.0527008892145706, 'max_iter': 1919, 'tol': 0.0015241377448979765, 'random_state': 906652, 'window_size': 8, 'confirmed_error': 8.264506555201208e-05, 'deaths_error': 0.00017968191404611904}\n",
      "\n",
      "{'alpha': 1.0527008892145706, 'max_iter': 1919, 'tol': 0.0015241377448979765, 'random_state': 906652, 'window_size': 8, 'confirmed_error': 8.264506555201208e-05, 'deaths_error': 0.00017968191404611904}\n",
      "\n",
      "{'alpha': 1.8381037054483904, 'max_iter': 2986, 'tol': 0.0012648811860279752, 'random_state': 75529, 'window_size': 4, 'confirmed_error': 8.000969883068725e-05, 'deaths_error': 0.0001782893056527195}\n",
      "\n",
      "{'alpha': 1.725823170197946, 'max_iter': 2171, 'tol': 0.00667999073950969, 'random_state': 43448, 'window_size': 6, 'confirmed_error': 9.138337344401038e-05, 'deaths_error': 0.00017420171962008045}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for setup in best_parameter_setups:\n",
    "        print(setup)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'submission' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-5b6802285835>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#submission = test.drop(columns=['Date', 'Province_State'])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubmission\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"team31-dec1-1-nosub.csv\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#submission.to_csv(filename)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'submission' is not defined"
     ]
    }
   ],
   "source": [
    "#submission = test.drop(columns=['Date', 'Province_State'])\n",
    "print(submission)\n",
    "filename = \"team31-dec1-1-nosub.csv\"\n",
    "#submission.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(MAPE(bestsub[['Confirmed', 'Deaths']], validation[['Confirmed', 'Deaths']]))\n",
    "print(\"Error of current run\")\n",
    "print(MAPE(test[['Confirmed', 'Deaths']], validation[['Confirmed', 'Deaths']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['Confirmed']=bestsub['Confirmed']\n",
    "submission['Deaths']=test['Deaths']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
