{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import numpy as np\n",
    "import sklearn \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy.integrate import odeint\n",
    "from scipy.optimize import minimize\n",
    "from utility_code.utility import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainrd2 = pd.read_csv(\"train_round2.csv\")\n",
    "datestofind = trainrd2['Date'] == '09-01-2020'\n",
    "start = datestofind[datestofind == True].index[0]\n",
    "datestofind2 = trainrd2['Date'] == '09-26-2020'\n",
    "end = datestofind[datestofind == True].index[49]\n",
    "\n",
    "bestsub = pd.read_csv(\"team31-nov29-2.csv\")\n",
    "\n",
    "validation = trainrd2.iloc[start:end,:]\n",
    "def MAPE(pred, valid):\n",
    "    pred = pred.reset_index()\n",
    "    valid = valid.reset_index()\n",
    "    pred = pred.astype('int64')\n",
    "    valid = valid.astype('int64')\n",
    "    v = pred.subtract(valid)\n",
    "    v = v.divide(valid)\n",
    "    v = v.abs()\n",
    "    v = v.sum(axis = 0)\n",
    "    #v = v[0]+v[1]+v[2]\n",
    "    n = len(pred)\n",
    "    return v/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import csvs\n",
    "train = pd.read_csv(\"ucla2020-cs145-covid19-prediction/train.csv\")\n",
    "test = pd.read_csv(\"ucla2020-cs145-covid19-prediction/test.csv\")\n",
    "graph = pd.read_csv(\"ucla2020-cs145-covid19-prediction/graph.csv\")\n",
    "supp = pd.read_csv(\"data-test/raw_data_test.csv\", skiprows=2, thousands=',')\n",
    "supp = supp[supp['Location'].isin(train['Province_State'])]\n",
    "supp['Population'] = supp['Number of COVID-19 Cases'].divide(supp['COVID-19 Cases per 1,000,000 Population']) * 1e6\n",
    "\n",
    "states = pd.Series.unique(train['Province_State'])\n",
    "num_states = len(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting using previous best setup...\n",
      "(*) SETUP: Confirmed Error: 0.00011500720358311134  | Deaths Error: 0.0002030049610670227\n",
      "(*) ITERATION 1: Confirmed Error: 9.021148701762243e-05  | Deaths Error: 0.00018716125052582158\n",
      "(*) ITERATION 2: Confirmed Error: 8.65948901791063e-05  | Deaths Error: 0.00020134893476889297\n",
      "(-) ITERATION 3: Confirmed Error: 9.380603181791952e-05  | Deaths Error: 0.00019881652070787413\n",
      "(*) ITERATION 4: Confirmed Error: 7.853518531358507e-05  | Deaths Error: 0.000200763945454092\n",
      "(*) ITERATION 5: Confirmed Error: 9.01115629239451e-05  | Deaths Error: 0.0001864774898420609\n",
      "(-) ITERATION 6: Confirmed Error: 8.743342342353557e-05  | Deaths Error: 0.000189441955911648\n",
      "(-) ITERATION 7: Confirmed Error: 0.0001377297424940892  | Deaths Error: 0.000202155777315817\n",
      "(-) ITERATION 8: Confirmed Error: 0.0001377297424940892  | Deaths Error: 0.00019754960504497402\n",
      "(-) ITERATION 9: Confirmed Error: 8.220371117259958e-05  | Deaths Error: 0.0001974552273411966\n",
      "(-) ITERATION 10: Confirmed Error: 8.192244533510936e-05  | Deaths Error: 0.0001940211614071307\n",
      "(-) ITERATION 11: Confirmed Error: 8.181886861790905e-05  | Deaths Error: 0.0001940211614071307\n"
     ]
    }
   ],
   "source": [
    "## MANIPULATES MODEL AND MODEL PARAMS\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "import random\n",
    "\n",
    "###################################################\n",
    "#TRY DIFFERENT VALUES FOR PARAMETERS AND KEEP THE BEST\n",
    "best_parameter_setup = { 'alpha': 25,\n",
    "                         'max_iter': 10000,\n",
    "                         'tol': 0.005,\n",
    "                         'random_state':1234567,\n",
    "                         'window_size':20,\n",
    "                         'confirmed_error': 7.667212448385207e-05,\n",
    "                         'deaths_error': 0.00016738204091735175  }\n",
    "\n",
    "best_parameter_setups = [best_parameter_setup]\n",
    "confirmed_error_best = 1 \n",
    "deaths_error_best = 1\n",
    "\n",
    "#returns sample taken from normal distribution, bounds the sample with min and max\n",
    "DEFAULT_MIN = 1e-25\n",
    "DEFAULT_MAX = 999999\n",
    "def normal_sample (mean,sd,mn,mx,rnd = False):\n",
    "    sample = max(mn, min(mx, np.random.normal(mean, sd)))\n",
    "    if rnd:\n",
    "        return int(sample)\n",
    "    else:\n",
    "        return sample\n",
    "\n",
    "\n",
    "ITERATIONS = 100\n",
    "parameter_setup = {}\n",
    "\n",
    "print(\"Starting using previous best setup...\")\n",
    "\n",
    "for it in range(ITERATIONS+1):\n",
    "    \n",
    "    #standard deviations: try increasing sd_scale for more variance (or decreasing for opposite effect)\n",
    "    sd_scale = 200 / len(best_parameter_setups) #sd goes down as more solutions are found\n",
    "    alpha_sd = 0.2 * sd_scale;\n",
    "    max_iter_sd = 100 * sd_scale;\n",
    "    tol_sd = 5e-4 * sd_scale;\n",
    "    \n",
    "    \n",
    "    #apply normal \"randomization\"\n",
    "    parameter_setup = {}\n",
    "    if it > 0:\n",
    "        parameter_setup['alpha'] = normal_sample( best_parameter_setups[-1]['alpha'], alpha_sd, DEFAULT_MIN, DEFAULT_MAX)\n",
    "        parameter_setup['max_iter'] = normal_sample( best_parameter_setups[-1]['max_iter'], max_iter_sd, 1, DEFAULT_MAX, rnd=True)\n",
    "        parameter_setup['tol'] = normal_sample( best_parameter_setups[-1]['tol'], tol_sd, DEFAULT_MIN, 20) \n",
    "        parameter_setup['random_state'] = random.randint(0,DEFAULT_MAX)\n",
    "        parameter_setup['window_size'] = random.randint(1,14)\n",
    "    else:\n",
    "        parameter_setup = best_parameter_setups[-1]\n",
    "    \n",
    "    \n",
    "    #choose a regressor\n",
    "    reg = MultiOutputRegressor(estimator=Ridge(\n",
    "                                    alpha=parameter_setup['alpha'],\n",
    "                                    max_iter=parameter_setup['max_iter'],\n",
    "                                    tol=parameter_setup['tol'],\n",
    "                                    random_state = parameter_setup['random_state']))\n",
    "        \n",
    "###################################################\n",
    "\n",
    "    ## MANIPULATES FEATURES FROM DF TO USE AND WINDOW SIZE\n",
    "    #only look at the features in features list\n",
    "    features = ['Confirmed','Deaths']\n",
    "    num_features = len(features)\n",
    "\n",
    "    #stratify by state (into state dictionary)\n",
    "    statesdata = {}\n",
    "    for s in states:\n",
    "        statesdata[s] = train.loc[train['Province_State'] == s,features]\n",
    "\n",
    "    \n",
    "    ###################################################\n",
    "    WINDOW_SIZE = parameter_setup['window_size']\n",
    "    ###################################################\n",
    "    \n",
    "    state_feature_indices = utils.get_column_indices(statesdata['California'],features)\n",
    "\n",
    "    #append the feature spaces from the W days prior (where W is the window length)\n",
    "    new_features = []\n",
    "    for day in range(WINDOW_SIZE):\n",
    "        for f in features:\n",
    "            new_features.append(f + \"(-\"+ str(WINDOW_SIZE-day) + \" days)\")\n",
    "    all_new_features = new_features + features\n",
    "\n",
    "    ## Set up dictionary of projections\n",
    "    proj = {}\n",
    "\n",
    "    ## Loop over states\n",
    "    for s in states:\n",
    "\n",
    "        a = statesdata[s]\n",
    "\n",
    "        #fill the knn data using days from training set\n",
    "        knndata = pd.DataFrame(columns = all_new_features)\n",
    "        num_training_days = len(statesdata['California'])\n",
    "\n",
    "        #fill the table\n",
    "        for d in range(WINDOW_SIZE,num_training_days):\n",
    "            knndata_row_index = knndata.shape[0]\n",
    "            knn_row = utils.flatten_dataframe(a,slice(d-WINDOW_SIZE,d+1), state_feature_indices)\n",
    "            utils.dataframe_append_row(knndata,knn_row,s,d)   \n",
    "\n",
    "        # Actual recursive prediction\n",
    "        days_to_predict = 26\n",
    "        for d in range(days_to_predict):\n",
    "            #x = knndata.drop(columns=features)\n",
    "            #y = knndata.drop(columns=features)\n",
    "            x = knndata.drop(['Confirmed', 'Deaths'], axis = 1)\n",
    "            y = knndata[['Confirmed', 'Deaths']]\n",
    "            toguess = 1\n",
    "            trainx = x.head(len(x))\n",
    "            trainy = y.head(len(y))\n",
    "            # testy = y.tail(toguess)\n",
    "\n",
    "            reg.fit(trainx, trainy)\n",
    "\n",
    "            #rmv = [i for i in range(num_features)]\n",
    "            #ftrs = knndata.drop(columns=knndata.columns[rmv]).tail(1)\n",
    "            ftrs = knndata.drop(columns=knndata.columns[[0,1]]).tail(1)\n",
    "            #ftrs.drop(columns=knndata.columns[[0,1]])\n",
    "\n",
    "            ftrs.columns = knndata.columns[0:num_features*WINDOW_SIZE]\n",
    "\n",
    "            new = reg.predict(ftrs)\n",
    "            ftrs = np.append(ftrs, new)\n",
    "            ftrs = ftrs.astype(int)\n",
    "            #if d==0: print(ftrs)\n",
    "            knndata = knndata.append(dict(zip(knndata.columns, ftrs)), ignore_index=True)\n",
    "\n",
    "            # append to knndata\n",
    "            #if d == 0: \n",
    "                #print(knndata)\n",
    "        done = knndata.tail(days_to_predict)\n",
    "        done = done[['Confirmed', 'Deaths']]\n",
    "        #print(done)\n",
    "        proj[s] = done\n",
    "\n",
    "    ## Get ordering of states in test    \n",
    "    order = test.loc[0:49,'Province_State']\n",
    "\n",
    "    # format submission\n",
    "    conf = []\n",
    "    dead = []\n",
    "    fid = 0\n",
    "    for i in range(days_to_predict):\n",
    "        for j in order:\n",
    "            projection = proj[j].iloc[i]\n",
    "            #print(j, 'day', i)\n",
    "            conf.append(int(projection['Confirmed']))\n",
    "            dead.append(int(projection['Deaths']))\n",
    "            #print(fid)\n",
    "            fid+=1\n",
    "\n",
    "    test['Confirmed'] = conf\n",
    "    test['Deaths'] = dead\n",
    "\n",
    "###################################################\n",
    "    errors = MAPE(test[['Confirmed', 'Deaths']], validation[['Confirmed', 'Deaths']])\n",
    "    parameter_setup['confirmed_error'] = errors['Confirmed']\n",
    "    parameter_setup['deaths_error'] = errors['Deaths']\n",
    "    \n",
    "    \n",
    "    found_good_sol = False\n",
    "    if(parameter_setup['confirmed_error'] < confirmed_error_best):\n",
    "        confirmed_error_best = parameter_setup['confirmed_error']\n",
    "        found_good_sol = True\n",
    "    if(parameter_setup['deaths_error'] < deaths_error_best):\n",
    "        deaths_error_best = parameter_setup['deaths_error']\n",
    "        found_good_sol = True\n",
    "    if found_good_sol:\n",
    "        best_parameter_setups.append(parameter_setup)\n",
    "        \n",
    "    if found_good_sol:\n",
    "        if it == 0:\n",
    "            print(\"(*) SETUP:\",\"Confirmed Error: \"+str(parameter_setup['confirmed_error']),\" | Deaths Error: \"+str(parameter_setup['deaths_error']))\n",
    "        else:\n",
    "            print(\"(*) ITERATION \"+str(it)+\":\",\"Confirmed Error: \"+str(parameter_setup['confirmed_error']),\" | Deaths Error: \"+str(parameter_setup['deaths_error']))\n",
    "    else:\n",
    "        if it == 0:\n",
    "            print(\"(-) SETUP:\",\"Confirmed Error: \"+str(parameter_setup['confirmed_error']),\" | Deaths Error: \"+str(parameter_setup['deaths_error']))\n",
    "        else:\n",
    "            print(\"(-) ITERATION \"+str(it)+\":\",\"Confirmed Error: \"+str(parameter_setup['confirmed_error']),\" | Deaths Error: \"+str(parameter_setup['deaths_error']))\n",
    "        \n",
    "        \n",
    "print(\"Found\",len(best_parameter_setups) - 1,\"good solutions!\")\n",
    "###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for setup in best_parameter_setups[1:]:\n",
    "        print(setup)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameter_setups[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission = test.drop(columns=['Date', 'Province_State'])\n",
    "print(submission)\n",
    "filename = \"team31-dec1-1-nosub.csv\"\n",
    "#submission.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(MAPE(bestsub[['Confirmed', 'Deaths']], validation[['Confirmed', 'Deaths']]))\n",
    "print(\"Error of current run\")\n",
    "print(MAPE(test[['Confirmed', 'Deaths']], validation[['Confirmed', 'Deaths']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['Confirmed']=bestsub['Confirmed']\n",
    "submission['Deaths']=test['Deaths']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
